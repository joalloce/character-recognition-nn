{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><small>This notebook was made as a simple and concise way to explain my work process of creating a neural network that recognize letters of the alphabet. The code here might not run.<small><i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import fileManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [\"B\", \"C\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \"M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = fileManager.get_samples(\"./test_samples\")\n",
    "train_samples = fileManager.get_samples(\"./train_samples\")\n",
    "\n",
    "test_labels, test_data = utils.split_data_and_labels(test_samples)\n",
    "train_labels, train_data = utils.split_data_and_labels(train_samples)\n",
    "\n",
    "test_data = test_data.astype(np.float64)\n",
    "train_data = train_data.astype(np.float64)\n",
    "train_X = train_data\n",
    "test_X = test_data\n",
    "\n",
    "train_Y = utils.reshape_output(train_labels)\n",
    "test_Y = utils.reshape_output(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2500)\n",
      "(300, 10)\n",
      "(100, 2500)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape) # 300 training samples. 30 for each character\n",
    "print(train_Y.shape) \n",
    "print(test_X.shape) # 100 test samples. 10 for each character\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network is a 2-layer neural network.\n",
    "The input layer has 2500 nodes.\n",
    "The hidden layer has 250 nodes.\n",
    "The output layer has 10 nodes.\n",
    "\n",
    "The ranges of the starting weights are -0.3 to 0.3. No weights starts with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting weights ranges\n",
    "max_weight = 0.3\n",
    "min_weight = -0.3\n",
    "weight_range = 0.6\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    '''\n",
    "    Neural network\n",
    "    default values:\n",
    "     - iterations = 100\n",
    "     - hidden layer nodes = 250\n",
    "    '''\n",
    "\n",
    "    def __init__(self, layers=[2500, 250, 10], iterations=100) -> None:\n",
    "        self.iterations = iterations\n",
    "        '''\n",
    "        [0] input layer size\n",
    "        [1] hidden layer size\n",
    "        [2] output layer size\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        '''\n",
    "        [b1] first bias array\n",
    "        [W1] first weight array\n",
    "        [b2] second bias array\n",
    "        [W2] second weight array\n",
    "        '''\n",
    "        self.params = {}\n",
    "        self.X = None  # input\n",
    "        self.Y = None  # output\n",
    "        self.error = 0\n",
    "        self.numIterations = 0\n",
    "\n",
    "    def initialize(self):\n",
    "        '''\n",
    "        Initialize all the layers at 0\n",
    "        '''\n",
    "        self.params[\"b1\"] = np.zeros((self.layers[1]))\n",
    "        self.params[\"W1\"] = np.zeros((self.layers[0], self.layers[1]))\n",
    "        self.params[\"b2\"] = np.zeros((self.layers[2]))\n",
    "        self.params[\"W2\"] = np.zeros((self.layers[1], self.layers[2]))\n",
    "\n",
    "    def init_weights_randomly(self):\n",
    "        '''\n",
    "        Initialize weights with random between -0.3 to 0.3. no zeros allowed.\n",
    "        '''\n",
    "        self.numIterations = 0  # zero\n",
    "        self.error = 0  # zero\n",
    "\n",
    "        for i in range(self.layers[0]):\n",
    "            for j in range(self.layers[1]):\n",
    "                number = (np.random.randint(low=0, high=600)/1000) - max_weight\n",
    "                while number == 0.0:  # if random equals zero take another random\n",
    "                    number = (np.random.randint(\n",
    "                        low=0, high=600)/1000) - max_weight\n",
    "                self.params[\"W1\"][i][j] = number\n",
    "\n",
    "        for i in range(self.layers[1]):\n",
    "            for j in range(self.layers[2]):\n",
    "                number = (np.random.randint(low=0, high=600)/1000) - max_weight\n",
    "                while number == 0.0:  # if random equals zero take another random\n",
    "                    number = (np.random.randint(\n",
    "                        low=0, high=600)/1000) - max_weight\n",
    "                self.params[\"W2\"][i][j] = number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward Propagation is the series of computations performed by the neural network to make a prediction.\n",
    "\n",
    "First, calculate the first layer's bias by doing the weighted sum between the input and the first layer's weights. Perform the sigmoid activation function.\n",
    "Second, calculate the second layer's bias by doing the weighted sum between the bias and the second layer's weights. Perform the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_b2(self):\n",
    "    '''\n",
    "    Calculate the second bias\n",
    "    '''\n",
    "    for i in range(self.layers[2]):\n",
    "        Z = self.compute_net_sum_b2(i)\n",
    "        self.params[\"b2\"][i] = self.sigmoid(Z)\n",
    "\n",
    "\n",
    "def compute_net_sum_b2(self, position):\n",
    "    '''\n",
    "    Net sum of second bias. Depends on the second weights and the first bias\n",
    "    '''\n",
    "    sum = 0.0\n",
    "    for i in range(self.layers[1]):\n",
    "        sum += self.params[\"b1\"][i] * self.params[\"W2\"][i][position]\n",
    "\n",
    "    return sum\n",
    "\n",
    "\n",
    "def compute_b1(self):\n",
    "    '''\n",
    "    Calculate the first bias\n",
    "    '''\n",
    "    for i in range(self.layers[1]):\n",
    "        Z = self.compute_net_sum_b1(i)\n",
    "        self.params[\"b1\"][i] = self.sigmoid(Z)\n",
    "\n",
    "\n",
    "def compute_net_sum_b1(self, position):\n",
    "    '''\n",
    "    Net sum of first bias. Depends on the first weights and the input\n",
    "    '''\n",
    "    sum = 0.0\n",
    "    for i in range(self.layers[0]):\n",
    "        sum += self.X[i] * self.params[\"W1\"][i][position]\n",
    "\n",
    "    return sum\n",
    "\n",
    "\n",
    "def sigmoid(self, Z):\n",
    "    '''\n",
    "    Activation function\n",
    "    Sigmoid function\n",
    "    '''\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "\n",
    "def forward_propagation(self):\n",
    "    '''\n",
    "    Compute both first and second bias\n",
    "    '''\n",
    "    self.compute_b1()\n",
    "    self.compute_b2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error aka the loss function is a way of measuring how good a model's prediction is.\n",
    "The error function is the difference of the outputs and the true prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_error(self):\n",
    "    '''\n",
    "    Calculate the error of each output\n",
    "    '''\n",
    "    self.error = 0\n",
    "    for i in range(self.layers[2]):\n",
    "        self.error += abs(self.Y[i] - self.params[\"b2\"][i])\n",
    "\n",
    "\n",
    "def check_if_error_surpass_threshold(self, threshold):\n",
    "    '''\n",
    "    if error > threshold\n",
    "    '''\n",
    "    if (self.error/self.layers[2]) > threshold:\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is the process of training a neural network by updating its weights.\n",
    "\n",
    "First, calculate the first layer's weights by doing the adjust factor sum between the output and the second bias.\n",
    "Second, calculate the second layer's weights by doing the adjust factor sum between the second bias and the first bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust_W1(self, alpha):\n",
    "    '''\n",
    "    Compute the first weights. Depends on second bias factor, alpha and input\n",
    "    '''\n",
    "    for i in range(self.layers[1]):\n",
    "        sum = self.sum_b2_adjust_factor(i)\n",
    "        b2_factor = self.params[\"b1\"][i] * (1 - self.params[\"b1\"][i]) * sum\n",
    "        for j in range(self.layers[0]):\n",
    "            self.params[\"W1\"][j][i] += alpha * \\\n",
    "                b2_factor * self.X[j]\n",
    "\n",
    "\n",
    "def sum_b2_adjust_factor(self, position):\n",
    "    '''\n",
    "    Sum the second bias factor. Depends on second weights\n",
    "    '''\n",
    "    sum = 0\n",
    "    for i in range(self.layers[2]):\n",
    "        sum += self.get_b2_adjust_factor(i) * \\\n",
    "            self.params[\"W2\"][position][i]\n",
    "\n",
    "    return sum\n",
    "\n",
    "\n",
    "def adjust_W2(self, alpha):\n",
    "    '''\n",
    "    Compute the second weights. Depends on second bias factor, alpha and first bias\n",
    "    '''\n",
    "    for i in range(self.layers[2]):\n",
    "        b2_factor = self.get_b2_adjust_factor(i)\n",
    "        for j in range(self.layers[1]):\n",
    "            self.params[\"W2\"][j][i] += alpha * \\\n",
    "                b2_factor * self.params[\"b1\"][j]\n",
    "\n",
    "\n",
    "def get_b2_adjust_factor(self, position):\n",
    "    '''\n",
    "    Calculate the second bias factor\n",
    "    '''\n",
    "    return (self.Y[position] - self.params[\"b2\"][position]) * self.params[\"b2\"][position] * (1 - self.params[\"b2\"][position])\n",
    "\n",
    "\n",
    "def back_propagation(self, alpha):\n",
    "    '''\n",
    "    Adjust the first and the second weights\n",
    "    '''\n",
    "    self.adjust_W1(alpha)\n",
    "    self.adjust_W2(alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit function takes 2 parameters: the input and the output. It loops through a number of iterations and perform forward propagation, compute the error and back propagation for each sample.\n",
    "\n",
    "alpha is the learning rate.\n",
    "threshold is the margin error acceptable to not perform back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(self, train_X, train_Y, threshold, alpha):\n",
    "    '''\n",
    "    Fit method\n",
    "    '''\n",
    "    stop = False\n",
    "    while stop == False and self.numIterations < self.iterations:\n",
    "        self.numIterations += 1\n",
    "        stop = True\n",
    "        # train with all the samples\n",
    "        for i in range(len(train_X)):\n",
    "            print(\"Iteration\", self.numIterations, \"sample\", i+1)\n",
    "            # set the input and output\n",
    "            self.X = train_X[i]\n",
    "            self.Y = train_Y[i]\n",
    "\n",
    "            self.forward_propagation()\n",
    "            self.compute_error()\n",
    "\n",
    "            # perform an ajustment if error surpass threshold\n",
    "            if self.check_if_error_surpass_threshold(threshold):\n",
    "                stop = False\n",
    "                self.back_propagation(alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model with the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(self, X):\n",
    "    '''\n",
    "    Make a prediction\n",
    "    '''\n",
    "    self.X = X\n",
    "    self.forward_propagation()  # performs a foward propagation\n",
    "    return self.params[\"b2\"]  # output\n",
    "\n",
    "\n",
    "def accuracy(self, Y):\n",
    "    '''\n",
    "    Calculate the accuracy of the output and the expected Y\n",
    "    '''\n",
    "    sum = 0.0\n",
    "    for i in range(self.layers[2]):\n",
    "        sum += abs(Y[i] - self.params[\"b2\"][i])\n",
    "    return 1 - (sum/self.layers[2])\n",
    "\n",
    "\n",
    "def test(self, test_X, test_Y):\n",
    "    '''\n",
    "    Test all the test samples. Calculates metrics\n",
    "    '''\n",
    "    match_counter = 0  # number of tests correctly predicted\n",
    "    sum = 0.0  # sum of accuracies\n",
    "    length = len(test_X)\n",
    "    for i in range(length):\n",
    "        prediction_vector = self.predict(test_X[i])  # predict\n",
    "        index = prediction_vector.tolist().index(np.max(prediction_vector))\n",
    "        prediction = utils.get_letter_from_index(index)  # letter predicted\n",
    "        index = test_Y[i].tolist().index(np.max(test_Y[i]))\n",
    "        expected = utils.get_letter_from_index(index)  # letter expected\n",
    "        if expected == prediction:\n",
    "            match_counter += 1\n",
    "\n",
    "        acc = self.accuracy(test_Y[i])  # calculate the accuracy\n",
    "        sum += acc\n",
    "        print(\"Test\", i + 1, \"Prediction:\", prediction,\n",
    "              \"Expected:\", expected)\n",
    "\n",
    "    print(\"Average Accuracy:\", round((sum/length) * 100, 2), \"%\")\n",
    "    print(\"Predicted\", match_counter, \"from\", length,\n",
    "          \"Performance:\", round((match_counter/length) * 100, 2), \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52ba17941256ee65bd296c645a576789f520bd10e85c9961ce82eb586611edc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
